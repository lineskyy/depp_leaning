{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 미세조정(Fine Tuning)\n","- 사전 학습되어있는 모델의 가중치를 이용하여 새로운 문제를 해결하기위해 최소한의 가중치를 추가해서 모델을 추가로 학습하는 방법"],"metadata":{"id":"QOustfyHG758"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"0dKf8KMcHhDl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import torch\n","from tqdm.auto import tqdm\n","import random # 시드 고정을 위해\n","import os # 시드 고정을 위해\n","\n","def reset_seeds(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)    # 파이썬 환경변수 시드 고정\n","    np.random.seed(seed)\n","    torch.manual_seed(seed) # cpu 연산 무작위 고정\n","    torch.cuda.manual_seed(seed) # gpu 연산 무작위 고정\n","    torch.backends.cudnn.deterministic = True  # cuda 라이브러리에서 Deterministic(결정론적)으로 예측하기 (예측에 대한 불확실성 제거 )"],"metadata":{"id":"S4ZUl0blyICB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 경로를 변경하시오"],"metadata":{"id":"vYgbHRL6x0Jj"}},{"cell_type":"code","source":["DATA_PATH = \"/content/drive/MyDrive/data/\"\n","SEED = 42\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"DCw16iecHhAU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(f\"{DATA_PATH}imdb.csv\")\n","df.head()"],"metadata":{"id":"0-HZ95piHg9t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"45sR1FxEk1g6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 전이학습 실습해보기"],"metadata":{"id":"iBTFzN_a2RyP"}},{"cell_type":"code","source":["model_name = \"bert-base-uncased\""],"metadata":{"id":"VLppbMqd1fr7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"],"metadata":{"id":"J_R-fFsP1foU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사전학습모델 토크나이저\n","- add_special_tokens\n","    - True: 특수 토큰 포함하겠다.\n","- max_length\n","    -  문장의 최대 길이 조절\n","- padding\n","    - max_length : 모델이 입력받을수 있는 최대 길이로 패딩\n","    - True : 패딩 여부\n","- truncation\n","    - True : 문장이 최대길이를 넘으면 자르겟다.\n"],"metadata":{"id":"6RDHoOzK2rNr"}},{"cell_type":"code","source":["token = tokenizer(df[\"review\"][0], add_special_tokens=True,padding=\"max_length\", truncation=True)\n","token"],"metadata":{"id":"Bzu0w6w85l2x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습데이터와 정답 데이터 생성"],"metadata":{"id":"oy07XVQZysO6"}},{"cell_type":"code","source":["train = df[\"review\"].to_numpy()\n","target = df[\"sentiment\"].to_numpy().reshape(-1,1)\n","train.shape , target.shape"],"metadata":{"id":"IZJxX3uO8vr6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터셋"],"metadata":{"id":"EicryyGhy2sL"}},{"cell_type":"code","source":["class ReviewDataset(torch.utils.data.Dataset):\n","    def __init__(self ,tokenizer , x, y = None ): \n","        self.tokenizer = tokenizer\n","        self.x = x\n","        self.y = y\n","    def __len__(self): \n","        return self.x.shape[0]\n","    def __getitem__(self, idx): \n","        item = {}\n","        item[\"x\"] = self.__tokenizer(self.x[idx]) \n","        if self.y is not None:\n","            item[\"y\"] = torch.Tensor(self.y[idx])\n","        return item\n","    def __tokenizer(self,text):\n","        inputs = self.tokenizer(text, add_special_tokens=True,padding=\"max_length\", truncation=True)\n","        for k, v in inputs.items(): \n","            inputs[k] = torch.LongTensor(v) \n","        return inputs"],"metadata":{"id":"wt2lX7nf9jyH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dt = ReviewDataset(tokenizer,train,target)\n","dl = torch.utils.data.DataLoader(dt, batch_size=1,shuffle=False) \n","batch = next(iter(dl))\n","batch"],"metadata":{"id":"pUsrSyzv1fiN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사전학습모델 생성"],"metadata":{"id":"LVilojYXzDIp"}},{"cell_type":"code","source":["model = AutoModel.from_pretrained(model_name)"],"metadata":{"id":"QuCN43Jt1N6d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch[\"x\"].keys()"],"metadata":{"id":"xpywK09I-503"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = model(**batch[\"x\"])\n","outputs.keys()"],"metadata":{"id":"h7C49YXl1N3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs[\"last_hidden_state\"].shape "],"metadata":{"id":"VizqAJ7V1N0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs[\"pooler_output\"].shape "],"metadata":{"id":"K5jf1O9G1Nx0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs[0].shape , outputs[1].shape "],"metadata":{"id":"hdcs8wWW1Nuz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델"],"metadata":{"id":"Djq_LuZRzRc0"}},{"cell_type":"code","source":["class Net(torch.nn.Module):\n","    def __init__(self, model_name): \n","        super().__init__()\n","        self.model = AutoModel.from_pretrained(model_name)\n","        self.output_layer = torch.nn.Linear(self.model.config.hidden_size, 1)\n","    def forward(self, x):\n","        x = self.model(**x) \n","        x = self.output_layer(x[1])\n","        return x"],"metadata":{"id":"J-sD7Hn91Nr8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Net(model_name)\n","model(batch[\"x\"]) "],"metadata":{"id":"8rU9B5ji1NpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_loop(dataloader,model,loss_fn,optimizer,device):\n","    epoch_loss = 0 \n","    model.train()\n","    for batch in tqdm(dataloader): \n","        pred = model(batch[\"x\"].to(device))\n","        loss = loss_fn(pred, batch[\"y\"].to(device)) \n","        \n","        optimizer.zero_grad() \n","        loss.backward()  \n","        optimizer.step() \n","        \n","        epoch_loss += loss.item() \n","\n","    epoch_loss /= len(dataloader) \n","\n","    return epoch_loss "],"metadata":{"id":"rXuRgNRa1NmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@torch.no_grad() \n","def test_loop(dataloader,model,loss_fn,device): \n","    epoch_loss = 0\n","    model.eval() \n","\n","    pred_list = []\n","    sig = torch.nn.Sigmoid()\n","\n","    for batch in tqdm(dataloader):\n","        \n","        pred = model(batch[\"x\"].to(device))\n","        if batch.get(\"y\") is not None: \n","            loss = loss_fn(pred, batch[\"y\"].to(device))\n","            epoch_loss += loss.item()\n","        \n","        pred = sig(pred)\n","        pred = pred.to(\"cpu\").numpy()\n","        pred_list.append(pred)\n","\n","    epoch_loss /= len(dataloader)\n","\n","    pred = np.concatenate(pred_list) \n","    return epoch_loss , pred "],"metadata":{"id":"uCd4AorX1Ni7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_splits = 5\n","epochs = 20\n","batch_size = 16 \n","loss_fn = torch.nn.BCEWithLogitsLoss()"],"metadata":{"id":"rM12E1-reJ1r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import KFold\n","cv = KFold(n_splits=n_splits,shuffle=True, random_state=SEED)"],"metadata":{"id":"9lrgU6ebEftj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score"],"metadata":{"id":"R96p1k5tEfqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 학습"],"metadata":{"id":"YJVrqYzZzoeY"}},{"cell_type":"code","source":["is_holdout = True\n","reset_seeds(SEED)\n","best_score_list = []\n","for i,(tri,vai) in enumerate(cv.split(train)):\n","    \n","    model = Net(model_name).to(device)\n","    optimizer = torch.optim.Adam(model.parameters()) \n","\n","    train_dt = ReviewDataset(tokenizer,train[tri],target[tri])\n","    valid_dt = ReviewDataset(tokenizer,train[vai],target[vai])\n","    train_dl = torch.utils.data.DataLoader(train_dt, batch_size=batch_size, shuffle=True)\n","    valid_dl = torch.utils.data.DataLoader(valid_dt, batch_size=batch_size,shuffle=False)\n","\n","    best_score = 0\n","    patience = 0\n","\n","    for epoch in range(epochs):\n","        \n","        train_loss = train_loop(train_dl, model, loss_fn,optimizer,device )\n","        valid_loss , pred = test_loop(valid_dl, model, loss_fn,device  )\n","        pred = (pred > 0.5).astype(int) \n","\n","        score = accuracy_score(target[vai],pred )\n","        patience += 1\n","        print(train_loss,valid_loss,score,sep=\"\\t\") \n","        if best_score < score:\n","            patience = 0\n","            best_score = score\n","            torch.save(model.state_dict(),f\"model_{i}.pth\")\n","\n","        if patience == 3:\n","            break\n","    \n","    best_score_list.append(best_score)\n","\n","    if is_holdout:\n","        break"],"metadata":{"id":"2cyBWpdrEfny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_zi-WUyKEfk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oxrNpoU6Efhb"},"execution_count":null,"outputs":[]}]}